
# CLASE 06-03-25
- Buscar siempre la mejor soluci√≥n a un problema, siempre va a encontrar la mejor soluci√≥n.
- Se utilizan √°rboles (la estructura) para buscar de manera ordenada y sistem√°tica
	- Ejemplos: Sin informaci√≥n (backtracking cronol√≥gica - Fuerza bruta), con informaci√≥n (mirar hacia el pasado, mirar hacia el futuro)
- ¬øQu√© es una metaheur√≠stica? 
	- Antes necesitamos saber **qu√© es una heur√≠stica**: 
		- Es una funci√≥n muy barata, y evalua las posibles decisiones que puedo tomar.
		- No usa aprendizaje, es la foto del momento.
		- Est√°n hechas para un problema en particular.
	- Meta: ‚ÄúM√°s all√°‚Äù (de nivel superior), heur√≠stica: ‚Äúencontrar‚Äù 
	- Por tanto las metaheur√≠sticas son t√©cnicas de prop√≥sito general no como las heur√≠sticas.
	- Pertenecen a un grupo de t√©cnicas llamadas incompletas.
- NP-HARD: Problemas de computacion muy dificiles que no tienen de momento una soluci√≥n(Algoritmo) que lo resuelva en un tiempo no exponencial, aqu√≠ acudir√≠a a una metaheur√≠stica.
- Tipo de problemas que abordaremos
	- Problemas Combinatoriales: Optimizaci√≥n y satisfacci√≥n con restricciones. 
	- Problemas Continuos: Lo mismo a lo anterior.
	- Sin restricciones (recordar funciones de costo ‚ÄúJ‚Äù en machine learning.
- Algo que queda en el aire‚Ä¶ 
	- ¬øQu√© queremos resolver? 
	- ¬øCu√°ndo aplicar cada t√©cnica? 
	- Necesitamos una metodolog√≠a: 
		- Conocer el problema 
		- Revisi√≥n del estado del arte 
		- Dise√±ar una t√©cnica 
		- Implementar 
		- Validar (experimentos) 
		- Concluir

FECHAS  (Se entregan o rinden)
- Tarea 1 -> Semana 24 marzo
- Tarea 2 y Control 1-> Semana 14 abril
- Tarea 3 -> Semana 19 mayo
- Tarea 4 y Control 2-> Semana 16 junio

# Clase 10-03-25
Exactos/Completas -> Mejor soluci√≥n
Metaheur√≠sticas/Incompletas - Buena soluci√≥n

Objetivos
- ‚ÄúRecordar‚Äù c√≥mo se realiza modelamiento. 
- Estudiar los tipos de problemas que veremos durante el curso. 
- Conocer las t√©cnicas empleadas para resolver instancias (benchmarks) de estos problemas.
¬øQu√© define el modelo de un problema?
- Una o m√°s variables 
- Dominios de cada variable, pueden ser discretos o continuos. 
- 0, 1 o m√°s restricciones. 
- 0, 1 o m√°s funciones objetivo. (Si puedo comparar las soluciones es porque tiene al menos una funci√≥n objetivo)
- Ejemplo: Un estudiante de la UDP desea dise√±ar un envase de lata para vender jugos en base a maqui. Supongamos que la lata debe tener forma cil√≠ndrica, en donde la superficie deber√° ser la menor posible, pero el volumen total de la lata deber√° ser de 128 ml.
	- Variables: Altura (h), radio (r)
	- Dominios: Numeros positivos h y r >0
	- Funci√≥n objetivo: Minimizar la superficie. 2pirh+2pir^2
	- Restricciones: hpir^2 = 128ml
## Problema de optimizaci√≥n con restricciones (COP)
- Se pueden tener restricciones de 2 tipos:
	- Restricciones de desigualdad
	- Restricciones de igualdad
- Se pueden tener muchas restricciones (m) y tambien muchas variables (n)
- g(x) hace referencia a las de desigualdad
- h(x) hace referencia a las de igualdad
- El objetivo es buscar valores en D (Dominio) que satisfagan las restricciones y que el valor de f sea m√°ximo o m√≠nimo (Seg√∫n sea el caso)
## Problema de satisfacci√≥n con restricciones (CSP)
- Exactamente lo mismo a lo anterior pero ya no tengo funcion objetivo, las soluciones no se puede comparar.
- El objetivo es encontrar una o todas las soluciones al problema.
## Soluciones y espacio de b√∫squeda
- **Soluci√≥n factible**: Corresponde a aquella soluci√≥n en donde, una vez asignado un valor a cada variable a partir del dominio, cumple con todas las restricciones del problema. 
- **Soluci√≥n infactible:** Corresponde a aquella soluci√≥n que no satisface una o m√°s restricciones del problema 
- Una vez que tenemos una soluci√≥n factible (en caso de existir), si estamos frente a un problema de optimizaci√≥n, la evaluamos utilizando la funci√≥n objetivo (medir calidad de la soluci√≥n). Si es un problema de minimizaci√≥n (resp. maximizaci√≥n), tratamos de buscar el menor (resp. mayor) valor de dicha funci√≥n. 
- Si es un problema de satisfacci√≥n, los limitaremos a encontrar soluciones, pues no las podemos comparar 
- **Espacio de b√∫squeda**: Corresponde a la regi√≥n en donde buscaremos las soluciones.
## Dificultad de los problemas 
- **Problemas –†**: Problemas que puedan ser resueltos en tiempo polinomial por una m√°quina de Turing determinista (todo algoritmo computacional puede ser emulado a trav√©s de una m√°quina de Turing). 
- **Problemas Œù–†**: No se conoce algoritmo que los resuelva en tiempo polinomial, pero dada una soluci√≥n se puede verificar en tiempo polinomial que esta es correcta. 
- En este curso abordaremos problemas del tipo Œù–†-Completo, que son los m√°s dif√≠ciles dentro de lo que es la categor√≠a anterior
## ¬øC√≥mo resolvemos este tipo de problemas?
- T√©cnicas exactas o completas
	- Con √°rboles
	- backtracking (no usa ning√∫n tipo de informaci√≥n, me equivoco voy un paso para atr√°s)
	- look-back (usan experiencia previa, para ver donde es el origen del error)
	- look-ahead(dado algo que hago ahora veo el impacto en el futuro)
- T√©cnicas de aproximaci√≥n o incompletas
	- B√∫squeda local
	- MH de trayectoria
	- Algoritmos evolutivos (MH poblaci√≥n)
	- Algoritmos de iteligencia de enjambre (MH de enjambre)
## EJEMPLO (ACTIVIDAD EN CLASE)
Suponga que el profe quiere viajar a Iquique con una maleta de bodega. Seg√∫n la normativa del aeropuerto, la maleta (con su contenido) puede pesar a lo m√°s 22 kg. Suponga que el profe debe elegir entre 1‚Ä¶n art√≠culos de ropa y 1‚Ä¶m videojuegos (cada pieza de ropa/juego tiene un peso distinto, todos conocidos). Adem√°s, el profe quiere llevar a lo m√°s 6 juegos y a lo menos 20 art√≠culos de ropa (aunque en la realidad, el profe llevar√≠a m√°s juegos que ropa üòÜ). Cada juego/art√≠culo tiene una cierta importancia (conocida) para el profe (distintos entre ellos), en donde si g_i > g_j implica que la importancia del juego/art√≠culo i tiene mayor importancia para el profesor.
	‚Ä¢	Construir el modelo: definir variables, dominios, restricciones, funciones objetivo.
	‚Ä¢	¬øCu√°l es el espacio¬†de¬†b√∫squeda?
	
- Variables:
	- Juegos J_i
	- Ropa R_j
- Par√°metros:
	- n, cantidad juegos
	- m, cantidad ropa
	- peso juego i (PJ_i)
	- peso ropa j (PR_i)
	- peso maximo ropa (22kg)
	- importancia juego i (g_i)
	- importancia ropa j (g_j)
- Dominios:
	- R_i y J_j pertenece [0,1]. Con i y j enteros.
- Restricciones:
	- sum(J_j) < =6
	- sum(R_i) > = 20
	- sum(J_ixPJ_i) + sum(R_jxPR_j) < = 22kg
- Funciones objetivos:
	- max sum(g_ixR_i) + sum(g_jxJ_j) 
	- maximizar cantidad de juegos/ropa importantes
- Espacio de b√∫squeda:
	- 2^(n+m), n cantidad de ropa, m cantidad de juegos. 2^n x 2^m 
# Clase 13-03-25
Con esta materia se puede resolver la pregunta 2 de la tarea, con la clase pasada se puede resolver la pregunta 1.

- Backtracking
	- CSP: N-Reinas
		- Posicionar en un tablero de N X N, N reinas de tal manera que no se ataquen entre ellas.
			- Considerando un tablero de 4 x 4, con 4 reinas
			- Definir variables y dominios
				- Variables: Ubicaciones
				- Dominio: 16
			- Definir restricciones
				- Q_i!=Q_j, con i y j pertenecientes a las columnas, (horizontal)
				- lo mismo pero en vertical
			- ¬øCu√°l es el espacio de b√∫squeda?: 16x16x16x16 = 16^4. Si se analiza por columna, sabiendo que no puede haber mas de una reina en una misma columna, el espacio de busqueda se reduce a 4x4x4x4 = 4^4
	- Proceso de b√∫squeda: 
		- B√∫squeda completa
			- Se explora el espacio de b√∫squeda del problema, de manera exhaustiva y ordenada
			- El proceso termina cuando:
				- Se encuentra una sokucion o todas(CSP), la √≥ptima (COP)
				- Se demuestra que no hay soluci√≥n
				- Se agotan los recursos computacionales (RAM)
				- Hay timeout
		- √Årbol
			- Elementos presentes:
				- Estado inicial: nodo ra√≠z, ejemplo: tablero vac√≠o sin reinas
				- Estado : Nodo que representa la ‚ÄúFoto‚Äù del momento de la b√∫squeda. Por ejemplo, ubicaci√≥n de las reinas. Los nodos no-hoja corresponden a soluciones incompletas. 
				- Acciones: A partir de un estado, que conjunto (finito) de acciones podemos realizar. Estas podr√≠an tener un costo asociado. Generan nodos hijo. 
				- Nodos hojas: si cumplen con las restricciones del problema, ser√≠an soluciones
			- Backtracking cronol√≥gico (BT)
				- Se realiza en profundidad 
				- En cada rama del √°rbol hacemos una asignaci√≥n, es decir le asignamos un valor a una variable o hacemos una acci√≥n dependiendo del problema. 
				- Cada vez que hacemos una asignaci√≥n debemos chequear si esta es consistente (Que cumpla con todas las restricciones del problema). Esto quiere decir que todas las otras variables tienen al menos un valor en su dominio que soporta dicha asignaci√≥n.
			- Backjumping 
				- ¬øHay alg√∫n problema con lo anterior? 
					- Si, como se puede ver en el ejemplo, la primera asignaci√≥n es incompatible con todas las decisiones posteriores. 
					- Generamos nodos innecesarios en la b√∫squeda. Esto es conocido como Thrashing. 
				- Una soluci√≥n: T√©cnicas Look-Back 
					- Hacer saltos hacia atr√°s m√°s eficientes (Backjumping) 
					- Salta a una variable responsable del bloqueo. 
					- No enumera algunas asignaciones parciales que no conducen a una posible soluci√≥n. 
					- Reduce el Thrashing. 
					- IMPORTANTE: Sigue siendo completa la b√∫squeda
			- Backjumping dirigido por conflictos (CBJ) 
				- Salta a la variable responsable del bloqueo 
				- No enumera algunas asignaciones parciales que no conducen a la soluci√≥n. 
				- Para cada variable, guardar el conjunto de conflictos Conf(xi ). (Se gasta un poco m√°s de memoria)
				- Por cada valor err√≥neo, registrar en Conf(xi ) la variable m√°s prematuramente instanciada (o todas las variables asociadas a la restricci√≥n donde est√© la m√°s prematuramente instanciada) y en conflicto con el intento actual de instanciaci√≥n. 
				- Cuando no queden valores por intentar, el conjunto entrega las causas del problema y el punto de regreso ser√° la variable m√°s reciente en el conjunto de conflictos
				- ![[Pasted image 20250313121452.png]]
				- Hemos llegado a un camino sin salida (deadend). Esto debido a que existe un vac√≠o de dominio (domain wipe-out) 
				- Dado que la √∫ltima variable que est√° en conflicto es X4 , entonces volvemos a ese punto del √°rbol. 
				- No se pierden soluciones en este proceso, es decir, la t√©cnica sigue siendo completa.
- EJERCICIO
	- Supongamos que deseamos pintar un autom√≥vil, cuyas partes son: Parachoques, Techo, Alerones, Carrocer√≠a, Puertas, Capot. Para esto tenemos los siguientes colores: Blanco, Rosado, Rojo, Negro. Sea A\B, A m√°s claro que B, entonces BLANCO\ROSADO\ROJO\NEGRO
	- Considere las sig. restricciones:
		- El parachoques debe ser blanco
		- El techo debe ser rojo
		- Los alerones no pueden ser ni blancos ni negros
		- La carrocer√≠a, las puertas y el capot deben ser del mismo color
		- El parachoques, el techo y los alerones deben ser m√°s claros que la carrocer√≠a
	- Utilice el algoritmo BT para encontrar (en caso de existir) una solucion
# Clase 17-03-25
## Forward checking
- Pertenece a un grupo de t√©cnicas clasificadas como T√©cnicas Look-Ahead. 
- Se basa en la idea de mirar hacia adelante en el √°rbol de b√∫squeda, para ver si al hacer una instanciaci√≥n hace imposible asignarle un valor a otra variable no instanciada. 
- Veamos c√≥mo se aplicar√≠a usando el ejemplo de las N-Reinas‚Ä¶
- Disminuye el trashing
- A pesar de que podr√≠an existir menos nodos en el √°rbol, se podr√≠an eventualmente realizar m√°s chequeos, en comparaci√≥n a las otras t√©cnicas estudiadas. 
- Continuar con el ejemplo‚Ä¶
- ¬øEs siempre FC mejor que eun BT simple? depende del tiempo
## MFC -Minimal Forward Checking-(Variante de forward checking)
- Es conocido tambi√©n por ‚ÄúLazy forward checking‚Äù 
- Revisa hacia adelante al igual que FC, sin embargo al encontrar un valor asignaci√≥n factible para una variable pasa inmediatamente a la otra. 
- De esta manera, eventualmente, podr√≠amos detectar vac√≠os de dominio (al igual que FC), pero sin realizar tantos chequeos. 
- Sigue siendo completo
## Orden de instanciaci√≥n
- El orden en el cual son instanciadas las variables afecta el tama√±o del √°rbol de b√∫squeda ‚Üí desempe√±o del algoritmo de b√∫squeda. 
- Heur√≠sticas de selecci√≥n de variable: Procedimiento generalmente no costoso computacionalmente, el cual tiene por objetivo seleccionar la siguiente variable a ser instanciada. Generalmente son tecnicas offline, y en este curso se centrar√° en t√©cnicas offline y no online.
- En general est√°n basadas en la premisa fail-first ‚ÄúPara tener √©xito, se debe intentar primero en donde m√°s probablemente se fallar√°‚Äù
## Heur√≠sticas de selecci√≥n de variable 
- Generalmente entre m√°s informaci√≥n utilicemos, mejor funcionar√°‚Äî> m√°s costo de CPU. 
- Algunos ejemplos (generales): 
	- Dom: Se selecciona la de menor dominio. 
	- Dom+Deg: Lo mismo que dom, sin embargo, si hay empate se elige aquella que aparece en m√°s restricciones. 
	- Dom/Deg: Se selecciona aquella que minimiza el cuociente dom/deg. 
- Dependiente del problema 
- Su propuesta‚Ä¶
## T√©cnicas de preproceso: Consistencia de arcos y nodos
- Antes de ver esto, es necesario saber ciertas propiedades de CSP/COP (se pueden demostrar, pero no lo veremos en este curso): 
	- Todo CSP/COP puede ser transformado a un conjunto de restricciones binarias y unarias. 
	- Todo CSP/COP con restricciones binarias y unarias puede ser modelado a trav√©s de un grafo. 
- Con lo anterior, podemos aplicar t√©cnicas de preproceso para CSP/COP: Nodo consistencia, Arco consistencia, Camino consistencia.

## Actividad
Dado el siguiente CSP:
X_1<X_2
X_2<X_3
X_3<X_1
X_4<X_2
X_1=X_4
X_1<X_2<X_3
X_3<X_1
x_1<x_3<x_1
con dominios D_i={1,2,3,4}
- Utilice el algoritmo Forward Checking para buscar todas las soluciones al problema. Utilice el orden X_1,X_2,X_3,X_4. ¬øExistir√° un orden de instanciaci√≥n/asignaci√≥n que permita reducir el √°rbol? si, X_3,X_2,X_1,X_4
	X_1 = {1,2,3,4}
	X_2 = {2,3,4}
	X_3 = {1}
	X_4 = {1,2,3,4}
- ¬øExistir√° un orden de instanciaci√≥n/asignaci√≥n que permita encontrar m√°s soluciones que la propuesta por ud.? No, ya que al ser un algoritmo completo no importa el orden, debe encontrar todas las soluciones

# Clase 24-03-25
- Algoritmos Greedy: Deterministas y Estoc√°sticos.
- Greedy randomized adaptive search procedure (GRASP)
## T√©cnicas de resoluci√≥n
- B√∫squeda aproximada (t√©cnicas incompletas): 
	- Normalmente estoc√°sticas. 
	- Entregan la mejor soluci√≥n encontrada sin garant√≠a de optimalidad. 
	- Capaces de manejarse en grandes espacios de b√∫squeda. 
	- No es necesario conocimiento a priori del problema.
- ![[Pasted image 20250324113842.png]]
- **Heur√≠sticas:**
	- Derivado del griego heuriskein: encontrar, descubrir
	- No garantizan encontrar la mejor soluci√≥n
	- Yo la dise√±o para el problema
	- Se requiere de alguien que sepa como funciona el problema y que sepa valorar que aspectos son importantes en el problema
	- El objetivo es resolver un problema r√°pidamente
- **Metaheur√≠sticas:**
	- Es una combinaci√≥n de heur√≠sticas, es una heur√≠stica pero m√°s general. Usa heur√≠sticas para buscar/construir soluciones.
	- No son dise√±adas para un problema especifico
	- No requiere de mucha informaci√≥n del problema a resolver.
	- **Problema:** requieren de tiempo para poder ajustar su(s) par√°metro(s).
- Dos tipos de t√©cnicas incompletas:
	- Constructivas:
		- No requieren de una soluci√≥n inicial.
		- Van construyendo una soluci√≥n: asignando iterativamente valores a las variables del problema.
		- Manejan soluciones parciales
	- Perturbadores
		- Requiere de una o varias soluciones iniciales
		- Modifican una soluci√≥n: Aplicando un movimiento o funci√≥n de vecindario
		- Manejan soluciones completas.
- Heur√≠sticas constructivas (Greddy o Voraces):
	- Son reglas locales para seleccionar los valores de las variables del problema
	- Utilizan la informaci√≥n del problema para definir estas reglas.
	- El objetivo es encontrar soluciones al problema de manera r√°pida.
	- **¬øQu√© necesitamos para definir un Greedy?** 
		- Representaci√≥n: Interpretaci√≥n de la estructura de la soluci√≥n. 
		- Funci√≥n de evaluaci√≥n o miope: Funci√≥n para evaluar la acci√≥n a realizar. 
	- Greedy determinista vs estoc√°stico: Determinista llega siempre a la misma soluci√≥n. Estoc√°stico‚Ä¶no. 
	- Greedy estoc√°stico: en vez de movernos a la mejor soluci√≥n, asignamos una probabilidad a las alternativas a partir de la funci√≥n miope.
	- **GRASP: Greedy Randomized Adaptive Search Procedure.**
		- Metaheur√≠stica la cual consiste en dos pasos: un greedy aleatorio y un algoritmo de b√∫squeda local. 
		- En vez de elegir la mejor alternativa con la funci√≥n miope, se hace un ranking con las alternativas posibles y le es asignado una probabilidad a cada una de ellas. De esta forma tendremos variabilidad en las soluciones. 
		- Una vez construida la soluci√≥n intentamos mejorarla utilizando b√∫squeda local. 
		- Existen muchas otras variantes: agregar ruido a las soluciones, a partir de soluciones parciales aplicar b√∫squeda local, entre otras. 
		- Tambi√©n se podr√≠a generar una poblaci√≥n (conjunto de soluciones) y utilizarla como soluciones iniciales en un algoritmo de este tipo.
# Clase 27-03-25
## Metaheur√≠sticas
- No garantizan el √≥ptimo global
- Pueden encontrar soluciones aceptables en tiempos razonables
- Cuando dise√±amos una metaheuristica nos encontramos con 2 criterios contradictorios:
	- Por un lado tenemos la **exploraci√≥n**: Deben buscarse zonas prometedoras del espacio de b√∫squeda. Tambi√©n se le conoce como **diversificaci√≥n**. 
	- Tambi√©n tenemos la **explotaci√≥n**: Centrar la b√∫squeda dentro de una regi√≥n en particular del espacio de b√∫squeda. Tambi√©n se le conoce como **intensificaci√≥n**.
	- De manera general lo mejor es primero explorar y luego explotar
- Hill Climbing
	- Tecnica de b√∫squeda local (Solo explota)
	- De soluci√≥n √∫nica que va cambiando en cada iteraci√≥n
	- Es pertubativo, es decir parto de una soluci√≥n inicial (factible o infactible) y esa va mejorando en el tiempo, esto lo hace mediante **operadores de movimiento** buscando que valor de la funci√≥n de dicha soluci√≥n sea mejor que la soluci√≥n actual mediante cambios minimos a la soluci√≥n, esto genera un vecinadario (conjunto de soluciones cercanas a la actual) luego me muevo a la mejor en base a la funcion objetivo y que cumpla con las restricciones.
	- Como manejar las coluciones infactibles? Reparar o penalizar (reparar es transformarmar la infactible a factible y la penalizaci√≥n le quita o agrega cosas a la funcion objetivo para cuando la solucion es infactible, agrega cuando es minimizar y quita cuando es maximizar.)
- Hill Climbing Mejor-Mejora
	-  Inicializaci√≥n: Crear una soluci√≥n a partir de alg√∫n criterio heur√≠stico o aleatorio. 
	- Mientras no se cumpla el criterio de parada (no hay mejora, tiempo, iteraciones,...) 
		- Generar vecindario a partir del movimiento elegido y conservar la mejor soluci√≥n del vecindario como soluci√≥n actual. 
	- Mostrar soluci√≥n + valor f.o + tiempo
- Hill Climbing Alguna-Mejora
	-  En algunas ocasiones nos encontraremos con problemas en que el vecindario de una soluci√≥n es muy grande. 
	- En tal caso, solo generamos el vecindario hasta el punto de encontrar la primera soluci√≥n que mejore la actual, en vez de generar el vecindario completo
- Hill Climbing con restart
	- Un gran problema de este algoritmo es que puede estancarse en √≥ptimos locales. 
	- La idea es recomenzar con el algoritmo con una nueva soluci√≥n cuando este se quede estancado. 
	- Desventaja del Hill-Climbing con restart: P√©rdida de informaci√≥n valiosa durante la b√∫squeda. 
	- ¬øQu√© pasa si utilizo Hill-Climbing con restart, creando la soluci√≥n inicial con un greedy determinista? Siempre llegar√° a lo mismo, ya que no es aleatorio.
# Clase 31-03-25
## Tabu Search
- Previene ciclos de corta duraci√≥n.
- Elementos claves de Tabu Search
	- Operador de movimiento
	- Soluci√≥n inicial
	- La representaci√≥n de la soluci√≥n
	- Funci√≥n de evaluacion (F.O)
	- Lista tab√∫
	- Criterio de aspiraci√≥n: Libera la b√∫squeda por medio de una funci√≥n de memoria a corto plazo (olvido estrat√©gico)
- La lista tab√∫ almacena movimientos prohibidos, en cada iteraci√≥n se elige el movimiento factible no-tab√∫. (memoria a corto plazo). Es del tipo FIFO
- Una lista tabu muy peque√±a, estoy explotando mucho m√°s
- Una lista tab√∫ muy grande, estoy explorando mucho m√°s
- El tama√±o de la lista depende del problema, se puede definir mediante pruebas evaluando la calidad de la soluci√≥n con un conjunto de pruebas (benchmarks)
- El algoritmo para de iterar segun el criterio definido, por ej: el tiempo transcurrido o la soluci√≥n no ha mejorado en cierta cantidad de iteraciones, etc.

EJERCICIO
La penalizacion ser√° de F.O+nx20 donde n es unidades de falla en restricciones.
- (x1,x4,x5,x6) -> F.O=16, infactible->F.0=56, Lista Tabu={} 
	Vecinadario (Remplazando x1 por todas las demas opciones)
	(x2,x4,x5,x6)-> F.O=19, infactible-> 39
	(x3,x4,x5,x6)-> F.O=28, factible 
	(x7,x4,x5,x6)-> F.O=27, factible->1ERA MEJOR
- (x7,x4,x5,x6)-> F.O=27, factible, Lista Tabu={(x1,x7)} 
	Vecinadario (Remplazando x4 por todas las demas opciones)
	(x7,x1,x5,x6)-> F.O=26, infactible->46
	(x7,x2,x5,x6)-> F.O=29, infactible-> 49
	(x7,x3,x5,x6)-> F.O=38, factible -> No es mejor que la mejor pero nos movemos
- (x7,x3,x5,x6)-> F.O=38, factible, Lista Tabu={(x1,x7),(x4,x3)} 
	Vecinadario (Remplazando x5 por todas las demas opciones)
	(x7,x3,x1,x6)-> F.O=44, factible
	(x7,x3,x2,x6)-> F.O=47, infactible->67
	(x7,x3,x4,x6)-> F.O=40, factible -> No es mejor que la mejor pero nos movemos
- (x7,x3,x4,x6)-> F.O=40, factible, Lista Tabu={(x4,x3),(x5,x4)}
	Vecinadario (Remplazando x6 por todas las demas opciones)
	(x7,x3,x4,x1)-> F.O=38, factible
	(x7,x3,x4,x2)-> F.O=41,factible
	(x7,x3,x4,x5)-> F.O=32, factible
Luego de 4 iteraciones la mejor solucion es:
(x7,x4,x5,x6)-> F.O=27, factible->1ERA MEJOR

# Clase 03-04-25
## Simulated Annealing
- Modelamiento del proceso de los cambios energ√©ticos en un sistema de part√≠culas conforme decrece la temperatura, hasta que converge a un estado estable (congelado).
- Incorpora una estrategia expl√≠cita para impedir √≥ptimos locales.
- Tiene una componente probabilistica
### Idea

- Permitir movimientos a soluciones que empeoren la F.O, de forma de poder escapar de los √≥ptimos locales
- Permitir movimientos que empeoren la calidad de la F.O de acuerdo a una probabilidad asociada a la temperatura del sistema.
- Parto con una temperatura alta y a medida que hay m√°s iteraciones la temperatura baja, de esta manera se puede explorar para luego explotar
- Mientras que las soluciones que mejoran la funci√≥n objetivo siempre son aceptadas, las soluciones que la empeoran son aceptadas con mayor probabilidad si la temperatura es m√°s alta.
## Probabilidad de aceptaci√≥n y temperatura
- De manera cl√°sica, la probabilidad de acepetaci√≥n sigue la distribuci√≥n de Boltzmann y solo se aplica cuando la nueva soluci√≥n es peor que la actual, si la nueva es mejor no aplica la probabilidad ya que solo te mueves.
- La temperatura es un par√°metro y determina la probabilidad de aceptaci√≥n de soluciones que no mejoran la soluci√≥n actual.
## Ingredientes para el SA
- Ingredientes de HC (representaci√≥n, evaluaci√≥n, operadores de vecindario) 
- Funci√≥n de probabilidad de aceptaci√≥n (Boltzmann) 
- Temperatura inicial y final 
- Proceso de enfriamiento: Esto es clave para la eficiencia y efectividad del algoritmo.
# Clase 07-04-25
## Algoritmos de trayectoria
- Iterated Local Search (ILS)
	- Dada una soluci√≥n s‚Äô, se aplica una perturbaci√≥n (random-walk) o peque√±o cambio. 
	- Luego, a partir de dicha nueva soluci√≥n, se aplica una b√∫squeda local, es decir, con operadores de movimiento buscar en la vecindad por mejores soluciones. Con esto llegamos a s‚Äô‚Äô 
	- Si s‚Äô‚Äô cumple con ciertos criterios (por ejemplo es ‚Äúmejor‚Äù que s‚Äô), entonces, ser√° nuestra nueva soluci√≥n y repetimos el proceso, si no, volvemos a s‚Äô. 
	- La clave est√° en la perturbaci√≥n: Si es peque√±a probablemente no mejore mucho, si es muy grande ser√° muy aleatoria la b√∫squeda.
- Large Neighbourhood Search (LNS)
	- Utiliza dos m√©todos: destroy y repair. 
	- El m√©todo destroy destruye parte de la soluci√≥n (estoc√°sticamente), mientras el m√©todo repair reconstruye la parte destruida. Dicho esto, el vecindario es definido como las soluciones a las cuales se puede llegar a partir de dicha nueva (incompleta) configuraci√≥n. 
	- Para la reparaci√≥n puede ser utilizado un m√©todo heur√≠stico.
# Tarea 2
- Son 2 casos, 1 con una pista y el otro con 2 pistas. Se hace todo para 1 pista, y luego todo para 2 pistas.
- El costo asociado por diferencia de tiempo respecto a preferente son 1 unidad de costo por cada minuto de tiempo.
- El componente restart en el grasp, no se debe hacer solo una unica vez, sino que se haga varias veces para ver como afecta ese reinicio en la soluci√≥n final. La cantidad de restart debe definirse mediante pruebas, para ver que valor da mejores resultados.
- En tabu y en SA, las 5 variaciones pueden ser 5 variaciones del tama√±o de la lista con saltos grandes, y en SA la temperatura con variaciones notorias.
- No es item necesario el modelamiento pero es util para una breve explicaci√≥n, no es requerido.