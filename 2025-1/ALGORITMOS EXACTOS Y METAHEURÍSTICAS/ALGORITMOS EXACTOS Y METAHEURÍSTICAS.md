
# CLASE 06-03-25
- Buscar siempre la mejor soluci√≥n a un problema, siempre va a encontrar la mejor soluci√≥n.
- Se utilizan √°rboles (la estructura) para buscar de manera ordenada y sistem√°tica
	- Ejemplos: Sin informaci√≥n (backtracking cronol√≥gica - Fuerza bruta), con informaci√≥n (mirar hacia el pasado, mirar hacia el futuro)
- ¬øQu√© es una metaheur√≠stica? 
	- Antes necesitamos saber **qu√© es una heur√≠stica**: 
		- Es una funci√≥n muy barata, y evalua las posibles decisiones que puedo tomar.
		- No usa aprendizaje, es la foto del momento.
		- Est√°n hechas para un problema en particular.
	- Meta: ‚ÄúM√°s all√°‚Äù (de nivel superior), heur√≠stica: ‚Äúencontrar‚Äù 
	- Por tanto las metaheur√≠sticas son t√©cnicas de prop√≥sito general no como las heur√≠sticas.
	- Pertenecen a un grupo de t√©cnicas llamadas incompletas.
- NP-HARD: Problemas de computacion muy dificiles que no tienen de momento una soluci√≥n(Algoritmo) que lo resuelva en un tiempo no exponencial, aqu√≠ acudir√≠a a una metaheur√≠stica.
- Tipo de problemas que abordaremos
	- Problemas Combinatoriales: Optimizaci√≥n y satisfacci√≥n con restricciones. 
	- Problemas Continuos: Lo mismo a lo anterior.
	- Sin restricciones (recordar funciones de costo ‚ÄúJ‚Äù en machine learning.
- Algo que queda en el aire‚Ä¶ 
	- ¬øQu√© queremos resolver? 
	- ¬øCu√°ndo aplicar cada t√©cnica? 
	- Necesitamos una metodolog√≠a: 
		- Conocer el problema 
		- Revisi√≥n del estado del arte 
		- Dise√±ar una t√©cnica 
		- Implementar 
		- Validar (experimentos) 
		- Concluir

FECHAS  (Se entregan o rinden)
- Tarea 1 -> Semana 24 marzo
- Tarea 2 y Control 1-> Semana 14 abril
- Tarea 3 -> Semana 19 mayo
- Tarea 4 y Control 2-> Semana 16 junio

# Clase 10-03-25
Exactos/Completas -> Mejor soluci√≥n
Metaheur√≠sticas/Incompletas - Buena soluci√≥n

Objetivos
- ‚ÄúRecordar‚Äù c√≥mo se realiza modelamiento. 
- Estudiar los tipos de problemas que veremos durante el curso. 
- Conocer las t√©cnicas empleadas para resolver instancias (benchmarks) de estos problemas.
¬øQu√© define el modelo de un problema?
- Una o m√°s variables 
- Dominios de cada variable, pueden ser discretos o continuos. 
- 0, 1 o m√°s restricciones. 
- 0, 1 o m√°s funciones objetivo. (Si puedo comparar las soluciones es porque tiene al menos una funci√≥n objetivo)
- Ejemplo: Un estudiante de la UDP desea dise√±ar un envase de lata para vender jugos en base a maqui. Supongamos que la lata debe tener forma cil√≠ndrica, en donde la superficie deber√° ser la menor posible, pero el volumen total de la lata deber√° ser de 128 ml.
	- Variables: Altura (h), radio (r)
	- Dominios: Numeros positivos h y r >0
	- Funci√≥n objetivo: Minimizar la superficie. 2pirh+2pir^2
	- Restricciones: hpir^2 = 128ml
## Problema de optimizaci√≥n con restricciones (COP)
- Se pueden tener restricciones de 2 tipos:
	- Restricciones de desigualdad
	- Restricciones de igualdad
- Se pueden tener muchas restricciones (m) y tambien muchas variables (n)
- g(x) hace referencia a las de desigualdad
- h(x) hace referencia a las de igualdad
- El objetivo es buscar valores en D (Dominio) que satisfagan las restricciones y que el valor de f sea m√°ximo o m√≠nimo (Seg√∫n sea el caso)
## Problema de satisfacci√≥n con restricciones (CSP)
- Exactamente lo mismo a lo anterior pero ya no tengo funcion objetivo, las soluciones no se puede comparar.
- El objetivo es encontrar una o todas las soluciones al problema.
## Soluciones y espacio de b√∫squeda
- **Soluci√≥n factible**: Corresponde a aquella soluci√≥n en donde, una vez asignado un valor a cada variable a partir del dominio, cumple con todas las restricciones del problema. 
- **Soluci√≥n infactible:** Corresponde a aquella soluci√≥n que no satisface una o m√°s restricciones del problema 
- Una vez que tenemos una soluci√≥n factible (en caso de existir), si estamos frente a un problema de optimizaci√≥n, la evaluamos utilizando la funci√≥n objetivo (medir calidad de la soluci√≥n). Si es un problema de minimizaci√≥n (resp. maximizaci√≥n), tratamos de buscar el menor (resp. mayor) valor de dicha funci√≥n. 
- Si es un problema de satisfacci√≥n, los limitaremos a encontrar soluciones, pues no las podemos comparar 
- **Espacio de b√∫squeda**: Corresponde a la regi√≥n en donde buscaremos las soluciones.
## Dificultad de los problemas 
- **Problemas –†**: Problemas que puedan ser resueltos en tiempo polinomial por una m√°quina de Turing determinista (todo algoritmo computacional puede ser emulado a trav√©s de una m√°quina de Turing). 
- **Problemas Œù–†**: No se conoce algoritmo que los resuelva en tiempo polinomial, pero dada una soluci√≥n se puede verificar en tiempo polinomial que esta es correcta. 
- En este curso abordaremos problemas del tipo Œù–†-Completo, que son los m√°s dif√≠ciles dentro de lo que es la categor√≠a anterior
## ¬øC√≥mo resolvemos este tipo de problemas?
- T√©cnicas exactas o completas
	- Con √°rboles
	- backtracking (no usa ning√∫n tipo de informaci√≥n, me equivoco voy un paso para atr√°s)
	- look-back (usan experiencia previa, para ver donde es el origen del error)
	- look-ahead(dado algo que hago ahora veo el impacto en el futuro)
- T√©cnicas de aproximaci√≥n o incompletas
	- B√∫squeda local
	- MH de trayectoria
	- Algoritmos evolutivos (MH poblaci√≥n)
	- Algoritmos de iteligencia de enjambre (MH de enjambre)
## EJEMPLO (ACTIVIDAD EN CLASE)
Suponga que el profe quiere viajar a Iquique con una maleta de bodega. Seg√∫n la normativa del aeropuerto, la maleta (con su contenido) puede pesar a lo m√°s 22 kg. Suponga que el profe debe elegir entre 1‚Ä¶n art√≠culos de ropa y 1‚Ä¶m videojuegos (cada pieza de ropa/juego tiene un peso distinto, todos conocidos). Adem√°s, el profe quiere llevar a lo m√°s 6 juegos y a lo menos 20 art√≠culos de ropa (aunque en la realidad, el profe llevar√≠a m√°s juegos que ropa üòÜ). Cada juego/art√≠culo tiene una cierta importancia (conocida) para el profe (distintos entre ellos), en donde si g_i > g_j implica que la importancia del juego/art√≠culo i tiene mayor importancia para el profesor.
	‚Ä¢	Construir el modelo: definir variables, dominios, restricciones, funciones objetivo.
	‚Ä¢	¬øCu√°l es el espacio¬†de¬†b√∫squeda?
	
- Variables:
	- Juegos J_i
	- Ropa R_j
- Par√°metros:
	- n, cantidad juegos
	- m, cantidad ropa
	- peso juego i (PJ_i)
	- peso ropa j (PR_i)
	- peso maximo ropa (22kg)
	- importancia juego i (g_i)
	- importancia ropa j (g_j)
- Dominios:
	- R_i y J_j pertenece [0,1]. Con i y j enteros.
- Restricciones:
	- sum(J_j) < =6
	- sum(R_i) > = 20
	- sum(J_ixPJ_i) + sum(R_jxPR_j) < = 22kg
- Funciones objetivos:
	- max sum(g_ixR_i) + sum(g_jxJ_j) 
	- maximizar cantidad de juegos/ropa importantes
- Espacio de b√∫squeda:
	- 2^(n+m), n cantidad de ropa, m cantidad de juegos. 2^n x 2^m 
# Clase 13-03-25
Con esta materia se puede resolver la pregunta 2 de la tarea, con la clase pasada se puede resolver la pregunta 1.

- Backtracking
	- CSP: N-Reinas
		- Posicionar en un tablero de N X N, N reinas de tal manera que no se ataquen entre ellas.
			- Considerando un tablero de 4 x 4, con 4 reinas
			- Definir variables y dominios
				- Variables: Ubicaciones
				- Dominio: 16
			- Definir restricciones
				- Q_i!=Q_j, con i y j pertenecientes a las columnas, (horizontal)
				- lo mismo pero en vertical
			- ¬øCu√°l es el espacio de b√∫squeda?: 16x16x16x16 = 16^4. Si se analiza por columna, sabiendo que no puede haber mas de una reina en una misma columna, el espacio de busqueda se reduce a 4x4x4x4 = 4^4
	- Proceso de b√∫squeda: 
		- B√∫squeda completa
			- Se explora el espacio de b√∫squeda del problema, de manera exhaustiva y ordenada
			- El proceso termina cuando:
				- Se encuentra una sokucion o todas(CSP), la √≥ptima (COP)
				- Se demuestra que no hay soluci√≥n
				- Se agotan los recursos computacionales (RAM)
				- Hay timeout
		- √Årbol
			- Elementos presentes:
				- Estado inicial: nodo ra√≠z, ejemplo: tablero vac√≠o sin reinas
				- Estado : Nodo que representa la ‚ÄúFoto‚Äù del momento de la b√∫squeda. Por ejemplo, ubicaci√≥n de las reinas. Los nodos no-hoja corresponden a soluciones incompletas. 
				- Acciones: A partir de un estado, que conjunto (finito) de acciones podemos realizar. Estas podr√≠an tener un costo asociado. Generan nodos hijo. 
				- Nodos hojas: si cumplen con las restricciones del problema, ser√≠an soluciones
			- Backtracking cronol√≥gico (BT)
				- Se realiza en profundidad 
				- En cada rama del √°rbol hacemos una asignaci√≥n, es decir le asignamos un valor a una variable o hacemos una acci√≥n dependiendo del problema. 
				- Cada vez que hacemos una asignaci√≥n debemos chequear si esta es consistente (Que cumpla con todas las restricciones del problema). Esto quiere decir que todas las otras variables tienen al menos un valor en su dominio que soporta dicha asignaci√≥n.
			- Backjumping 
				- ¬øHay alg√∫n problema con lo anterior? 
					- Si, como se puede ver en el ejemplo, la primera asignaci√≥n es incompatible con todas las decisiones posteriores. 
					- Generamos nodos innecesarios en la b√∫squeda. Esto es conocido como Thrashing. 
				- Una soluci√≥n: T√©cnicas Look-Back 
					- Hacer saltos hacia atr√°s m√°s eficientes (Backjumping) 
					- Salta a una variable responsable del bloqueo. 
					- No enumera algunas asignaciones parciales que no conducen a una posible soluci√≥n. 
					- Reduce el Thrashing. 
					- IMPORTANTE: Sigue siendo completa la b√∫squeda
			- Backjumping dirigido por conflictos (CBJ) 
				- Salta a la variable responsable del bloqueo 
				- No enumera algunas asignaciones parciales que no conducen a la soluci√≥n. 
				- Para cada variable, guardar el conjunto de conflictos Conf(xi ). (Se gasta un poco m√°s de memoria)
				- Por cada valor err√≥neo, registrar en Conf(xi ) la variable m√°s prematuramente instanciada (o todas las variables asociadas a la restricci√≥n donde est√© la m√°s prematuramente instanciada) y en conflicto con el intento actual de instanciaci√≥n. 
				- Cuando no queden valores por intentar, el conjunto entrega las causas del problema y el punto de regreso ser√° la variable m√°s reciente en el conjunto de conflictos
				- ![[Pasted image 20250313121452.png]]
				- Hemos llegado a un camino sin salida (deadend). Esto debido a que existe un vac√≠o de dominio (domain wipe-out) 
				- Dado que la √∫ltima variable que est√° en conflicto es X4 , entonces volvemos a ese punto del √°rbol. 
				- No se pierden soluciones en este proceso, es decir, la t√©cnica sigue siendo completa.
- EJERCICIO
	- Supongamos que deseamos pintar un autom√≥vil, cuyas partes son: Parachoques, Techo, Alerones, Carrocer√≠a, Puertas, Capot. Para esto tenemos los siguientes colores: Blanco, Rosado, Rojo, Negro. Sea A\B, A m√°s claro que B, entonces BLANCO\ROSADO\ROJO\NEGRO
	- Considere las sig. restricciones:
		- El parachoques debe ser blanco
		- El techo debe ser rojo
		- Los alerones no pueden ser ni blancos ni negros
		- La carrocer√≠a, las puertas y el capot deben ser del mismo color
		- El parachoques, el techo y los alerones deben ser m√°s claros que la carrocer√≠a
	- Utilice el algoritmo BT para encontrar (en caso de existir) una solucion
# Clase 17-03-25
## Forward checking
- Pertenece a un grupo de t√©cnicas clasificadas como T√©cnicas Look-Ahead. 
- Se basa en la idea de mirar hacia adelante en el √°rbol de b√∫squeda, para ver si al hacer una instanciaci√≥n hace imposible asignarle un valor a otra variable no instanciada. 
- Veamos c√≥mo se aplicar√≠a usando el ejemplo de las N-Reinas‚Ä¶
- Disminuye el trashing
- A pesar de que podr√≠an existir menos nodos en el √°rbol, se podr√≠an eventualmente realizar m√°s chequeos, en comparaci√≥n a las otras t√©cnicas estudiadas. 
- Continuar con el ejemplo‚Ä¶
- ¬øEs siempre FC mejor que eun BT simple? depende del tiempo
## MFC -Minimal Forward Checking-(Variante de forward checking)
- Es conocido tambi√©n por ‚ÄúLazy forward checking‚Äù 
- Revisa hacia adelante al igual que FC, sin embargo al encontrar un valor asignaci√≥n factible para una variable pasa inmediatamente a la otra. 
- De esta manera, eventualmente, podr√≠amos detectar vac√≠os de dominio (al igual que FC), pero sin realizar tantos chequeos. 
- Sigue siendo completo
## Orden de instanciaci√≥n
- El orden en el cual son instanciadas las variables afecta el tama√±o del √°rbol de b√∫squeda ‚Üí desempe√±o del algoritmo de b√∫squeda. 
- Heur√≠sticas de selecci√≥n de variable: Procedimiento generalmente no costoso computacionalmente, el cual tiene por objetivo seleccionar la siguiente variable a ser instanciada. Generalmente son tecnicas offline, y en este curso se centrar√° en t√©cnicas offline y no online.
- En general est√°n basadas en la premisa fail-first ‚ÄúPara tener √©xito, se debe intentar primero en donde m√°s probablemente se fallar√°‚Äù
## Heur√≠sticas de selecci√≥n de variable 
- Generalmente entre m√°s informaci√≥n utilicemos, mejor funcionar√°‚Äî> m√°s costo de CPU. 
- Algunos ejemplos (generales): 
	- Dom: Se selecciona la de menor dominio. 
	- Dom+Deg: Lo mismo que dom, sin embargo, si hay empate se elige aquella que aparece en m√°s restricciones. 
	- Dom/Deg: Se selecciona aquella que minimiza el cuociente dom/deg. 
- Dependiente del problema 
- Su propuesta‚Ä¶
## T√©cnicas de preproceso: Consistencia de arcos y nodos
- Antes de ver esto, es necesario saber ciertas propiedades de CSP/COP (se pueden demostrar, pero no lo veremos en este curso): 
	- Todo CSP/COP puede ser transformado a un conjunto de restricciones binarias y unarias. 
	- Todo CSP/COP con restricciones binarias y unarias puede ser modelado a trav√©s de un grafo. 
- Con lo anterior, podemos aplicar t√©cnicas de preproceso para CSP/COP: Nodo consistencia, Arco consistencia, Camino consistencia.

## Actividad
Dado el siguiente CSP:
X_1<X_2
X_2<X_3
X_3<X_1
X_4<X_2
X_1=X_4
X_1<X_2<X_3
X_3<X_1
x_1<x_3<x_1
con dominios D_i={1,2,3,4}
- Utilice el algoritmo Forward Checking para buscar todas las soluciones al problema. Utilice el orden X_1,X_2,X_3,X_4. ¬øExistir√° un orden de instanciaci√≥n/asignaci√≥n que permita reducir el √°rbol? si, X_3,X_2,X_1,X_4
	X_1 = {1,2,3,4}
	X_2 = {2,3,4}
	X_3 = {1}
	X_4 = {1,2,3,4}
- ¬øExistir√° un orden de instanciaci√≥n/asignaci√≥n que permita encontrar m√°s soluciones que la propuesta por ud.? No, ya que al ser un algoritmo completo no importa el orden, debe encontrar todas las soluciones

# Clase 24-03-25
- Algoritmos Greedy: Deterministas y Estoc√°sticos.
- Greedy randomized adaptive search procedure (GRASP)
## T√©cnicas de resoluci√≥n
- B√∫squeda aproximada (t√©cnicas incompletas): 
	- Normalmente estoc√°sticas. 
	- Entregan la mejor soluci√≥n encontrada sin garant√≠a de optimalidad. 
	- Capaces de manejarse en grandes espacios de b√∫squeda. 
	- No es necesario conocimiento a priori del problema.
- ![[Pasted image 20250324113842.png]]
- **Heur√≠sticas:**
	- Derivado del griego heuriskein: encontrar, descubrir
	- No garantizan encontrar la mejor soluci√≥n
	- Yo la dise√±o para el problema
	- Se requiere de alguien que sepa como funciona el problema y que sepa valorar que aspectos son importantes en el problema
	- El objetivo es resolver un problema r√°pidamente
- **Metaheur√≠sticas:**
	- Es una combinaci√≥n de heur√≠sticas, es una heur√≠stica pero m√°s general. Usa heur√≠sticas para buscar/construir soluciones.
	- No son dise√±adas para un problema especifico
	- No requiere de mucha informaci√≥n del problema a resolver.
	- **Problema:** requieren de tiempo para poder ajustar su(s) par√°metro(s).
- Dos tipos de t√©cnicas incompletas:
	- Constructivas:
		- No requieren de una soluci√≥n inicial.
		- Van construyendo una soluci√≥n: asignando iterativamente valores a las variables del problema.
		- Manejan soluciones parciales
	- Perturbadores
		- Requiere de una o varias soluciones iniciales
		- Modifican una soluci√≥n: Aplicando un movimiento o funci√≥n de vecindario
		- Manejan soluciones completas.
- Heur√≠sticas constructivas (Greddy o Voraces):
	- Son reglas locales para seleccionar los valores de las variables del problema
	- Utilizan la informaci√≥n del problema para definir estas reglas.
	- El objetivo es encontrar soluciones al problema de manera r√°pida.
	- **¬øQu√© necesitamos para definir un Greedy?** 
		- Representaci√≥n: Interpretaci√≥n de la estructura de la soluci√≥n. 
		- Funci√≥n de evaluaci√≥n o miope: Funci√≥n para evaluar la acci√≥n a realizar. 
	- Greedy determinista vs estoc√°stico: Determinista llega siempre a la misma soluci√≥n. Estoc√°stico‚Ä¶no. 
	- Greedy estoc√°stico: en vez de movernos a la mejor soluci√≥n, asignamos una probabilidad a las alternativas a partir de la funci√≥n miope.
	- **GRASP: Greedy Randomized Adaptive Search Procedure.**
		- Metaheur√≠stica la cual consiste en dos pasos: un greedy aleatorio y un algoritmo de b√∫squeda local. 
		- En vez de elegir la mejor alternativa con la funci√≥n miope, se hace un ranking con las alternativas posibles y le es asignado una probabilidad a cada una de ellas. De esta forma tendremos variabilidad en las soluciones. 
		- Una vez construida la soluci√≥n intentamos mejorarla utilizando b√∫squeda local. 
		- Existen muchas otras variantes: agregar ruido a las soluciones, a partir de soluciones parciales aplicar b√∫squeda local, entre otras. 
		- Tambi√©n se podr√≠a generar una poblaci√≥n (conjunto de soluciones) y utilizarla como soluciones iniciales en un algoritmo de este tipo.
# Clase 27-03-25
## Metaheur√≠sticas
- No garantizan el √≥ptimo global
- Pueden encontrar soluciones aceptables en tiempos razonables
- Cuando dise√±amos una metaheuristica nos encontramos con 2 criterios contradictorios:
	- Por un lado tenemos la **exploraci√≥n**: Deben buscarse zonas prometedoras del espacio de b√∫squeda. Tambi√©n se le conoce como **diversificaci√≥n**. 
	- Tambi√©n tenemos la **explotaci√≥n**: Centrar la b√∫squeda dentro de una regi√≥n en particular del espacio de b√∫squeda. Tambi√©n se le conoce como **intensificaci√≥n**.
	- De manera general lo mejor es primero explorar y luego explotar
- Hill Climbing
	- Tecnica de b√∫squeda local (Solo explota)
	- De soluci√≥n √∫nica que va cambiando en cada iteraci√≥n
	- Es pertubativo, es decir parto de una soluci√≥n inicial (factible o infactible) y esa va mejorando en el tiempo, esto lo hace mediante **operadores de movimiento** buscando que valor de la funci√≥n de dicha soluci√≥n sea mejor que la soluci√≥n actual mediante cambios minimos a la soluci√≥n, esto genera un vecinadario (conjunto de soluciones cercanas a la actual) luego me muevo a la mejor en base a la funcion objetivo y que cumpla con las restricciones.
	- Como manejar las coluciones infactibles? Reparar o penalizar (reparar es transformarmar la infactible a factible y la penalizaci√≥n le quita o agrega cosas a la funcion objetivo para cuando la solucion es infactible, agrega cuando es minimizar y quita cuando es maximizar.)
- Hill Climbing Mejor-Mejora
	-  Inicializaci√≥n: Crear una soluci√≥n a partir de alg√∫n criterio heur√≠stico o aleatorio. 
	- Mientras no se cumpla el criterio de parada (no hay mejora, tiempo, iteraciones,...) 
		- Generar vecindario a partir del movimiento elegido y conservar la mejor soluci√≥n del vecindario como soluci√≥n actual. 
	- Mostrar soluci√≥n + valor f.o + tiempo
- Hill Climbing Alguna-Mejora
	-  En algunas ocasiones nos encontraremos con problemas en que el vecindario de una soluci√≥n es muy grande. 
	- En tal caso, solo generamos el vecindario hasta el punto de encontrar la primera soluci√≥n que mejore la actual, en vez de generar el vecindario completo
- Hill Climbing con restart
	- Un gran problema de este algoritmo es que puede estancarse en √≥ptimos locales. 
	- La idea es recomenzar con el algoritmo con una nueva soluci√≥n cuando este se quede estancado. 
	- Desventaja del Hill-Climbing con restart: P√©rdida de informaci√≥n valiosa durante la b√∫squeda. 
	- ¬øQu√© pasa si utilizo Hill-Climbing con restart, creando la soluci√≥n inicial con un greedy determinista? Siempre llegar√° a lo mismo, ya que no es aleatorio.
# Clase 31-03-25
## Tabu Search
- Previene ciclos de corta duraci√≥n.
- Elementos claves de Tabu Search
	- Operador de movimiento
	- Soluci√≥n inicial
	- La representaci√≥n de la soluci√≥n
	- Funci√≥n de evaluacion (F.O)
	- Lista tab√∫
	- Criterio de aspiraci√≥n: Libera la b√∫squeda por medio de una funci√≥n de memoria a corto plazo (olvido estrat√©gico)
- La lista tab√∫ almacena movimientos prohibidos, en cada iteraci√≥n se elige el movimiento factible no-tab√∫. (memoria a corto plazo). Es del tipo FIFO
- Una lista tabu muy peque√±a, estoy explotando mucho m√°s
- Una lista tab√∫ muy grande, estoy explorando mucho m√°s
- El tama√±o de la lista depende del problema, se puede definir mediante pruebas evaluando la calidad de la soluci√≥n con un conjunto de pruebas (benchmarks)
- El algoritmo para de iterar segun el criterio definido, por ej: el tiempo transcurrido o la soluci√≥n no ha mejorado en cierta cantidad de iteraciones, etc.

EJERCICIO
La penalizacion ser√° de F.O+nx20 donde n es unidades de falla en restricciones.
- (x1,x4,x5,x6) -> F.O=16, infactible->F.0=56, Lista Tabu={} 
	Vecinadario (Remplazando x1 por todas las demas opciones)
	(x2,x4,x5,x6)-> F.O=19, infactible-> 39
	(x3,x4,x5,x6)-> F.O=28, factible 
	(x7,x4,x5,x6)-> F.O=27, factible->1ERA MEJOR
- (x7,x4,x5,x6)-> F.O=27, factible, Lista Tabu={(x1,x7)} 
	Vecinadario (Remplazando x4 por todas las demas opciones)
	(x7,x1,x5,x6)-> F.O=26, infactible->46
	(x7,x2,x5,x6)-> F.O=29, infactible-> 49
	(x7,x3,x5,x6)-> F.O=38, factible -> No es mejor que la mejor pero nos movemos
- (x7,x3,x5,x6)-> F.O=38, factible, Lista Tabu={(x1,x7),(x4,x3)} 
	Vecinadario (Remplazando x5 por todas las demas opciones)
	(x7,x3,x1,x6)-> F.O=44, factible
	(x7,x3,x2,x6)-> F.O=47, infactible->67
	(x7,x3,x4,x6)-> F.O=40, factible -> No es mejor que la mejor pero nos movemos
- (x7,x3,x4,x6)-> F.O=40, factible, Lista Tabu={(x4,x3),(x5,x4)}
	Vecinadario (Remplazando x6 por todas las demas opciones)
	(x7,x3,x4,x1)-> F.O=38, factible
	(x7,x3,x4,x2)-> F.O=41,factible
	(x7,x3,x4,x5)-> F.O=32, factible
Luego de 4 iteraciones la mejor solucion es:
(x7,x4,x5,x6)-> F.O=27, factible->1ERA MEJOR

# Clase 03-04-25
## Simulated Annealing
- Modelamiento del proceso de los cambios energ√©ticos en un sistema de part√≠culas conforme decrece la temperatura, hasta que converge a un estado estable (congelado).
- Incorpora una estrategia expl√≠cita para impedir √≥ptimos locales.
- Tiene una componente probabilistica
### Idea

- Permitir movimientos a soluciones que empeoren la F.O, de forma de poder escapar de los √≥ptimos locales
- Permitir movimientos que empeoren la calidad de la F.O de acuerdo a una probabilidad asociada a la temperatura del sistema.
- Parto con una temperatura alta y a medida que hay m√°s iteraciones la temperatura baja, de esta manera se puede explorar para luego explotar
- Mientras que las soluciones que mejoran la funci√≥n objetivo siempre son aceptadas, las soluciones que la empeoran son aceptadas con mayor probabilidad si la temperatura es m√°s alta.
## Probabilidad de aceptaci√≥n y temperatura
- De manera cl√°sica, la probabilidad de acepetaci√≥n sigue la distribuci√≥n de Boltzmann y solo se aplica cuando la nueva soluci√≥n es peor que la actual, si la nueva es mejor no aplica la probabilidad ya que solo te mueves.
- La temperatura es un par√°metro y determina la probabilidad de aceptaci√≥n de soluciones que no mejoran la soluci√≥n actual.
## Ingredientes para el SA
- Ingredientes de HC (representaci√≥n, evaluaci√≥n, operadores de vecindario) 
- Funci√≥n de probabilidad de aceptaci√≥n (Boltzmann) 
- Temperatura inicial y final 
- Proceso de enfriamiento: Esto es clave para la eficiencia y efectividad del algoritmo.
# Clase 07-04-25
## Algoritmos de trayectoria
- Iterated Local Search (ILS)
	- Dada una soluci√≥n s‚Äô, se aplica una perturbaci√≥n (random-walk) o peque√±o cambio. 
	- Luego, a partir de dicha nueva soluci√≥n, se aplica una b√∫squeda local, es decir, con operadores de movimiento buscar en la vecindad por mejores soluciones. Con esto llegamos a s‚Äô‚Äô 
	- Si s‚Äô‚Äô cumple con ciertos criterios (por ejemplo es ‚Äúmejor‚Äù que s‚Äô), entonces, ser√° nuestra nueva soluci√≥n y repetimos el proceso, si no, volvemos a s‚Äô. 
	- La clave est√° en la perturbaci√≥n: Si es peque√±a probablemente no mejore mucho, si es muy grande ser√° muy aleatoria la b√∫squeda.
- Large Neighbourhood Search (LNS)
	- Utiliza dos m√©todos: destroy y repair. 
	- El m√©todo destroy destruye parte de la soluci√≥n (estoc√°sticamente), mientras el m√©todo repair reconstruye la parte destruida. Dicho esto, el vecindario es definido como las soluciones a las cuales se puede llegar a partir de dicha nueva (incompleta) configuraci√≥n. 
	- Para la reparaci√≥n puede ser utilizado un m√©todo heur√≠stico.
# Tarea 2
- Son 2 casos, 1 con una pista y el otro con 2 pistas. Se hace todo para 1 pista, y luego todo para 2 pistas.
- El costo asociado por diferencia de tiempo respecto a preferente son 1 unidad de costo por cada minuto de tiempo.
- El componente restart en el grasp, no se debe hacer solo una unica vez, sino que se haga varias veces para ver como afecta ese reinicio en la soluci√≥n final. La cantidad de restart debe definirse mediante pruebas, para ver que valor da mejores resultados.
- En tabu y en SA, las 5 variaciones pueden ser 5 variaciones del tama√±o de la lista con saltos grandes, y en SA la temperatura con variaciones notorias.
- No es item necesario el modelamiento pero es util para una breve explicaci√≥n, no es requerido.


# Clase 12-05-25

## Repaso Clase 11 y 12

### Metaheur√≠sticas Basadas en Poblaciones (MH-P)

Hasta ahora, hemos explorado metaheur√≠sticas que mejoran iterativamente una √∫nica soluci√≥n, como Hill-Climbing (HC), Tabu Search (TS), y Simulated Annealing (SA). Ahora nos enfocamos en t√©cnicas que trabajan con un conjunto o **poblaci√≥n de soluciones** simult√°neamente. Estas pertenecen en su mayor√≠a a la categor√≠a estoc√°stica y suelen tener par√°metros que ajustar.

**Conceptos Comunes de MH-P:**
* Comienzan con una **poblaci√≥n inicial** de soluciones. La diversidad en esta poblaci√≥n es crucial para evitar la convergencia prematura. 
* Iterativamente, se genera un nuevo grupo de individuos y se actualiza la poblaci√≥n actual. 
* La generaci√≥n y reemplazo pueden o no involucrar memoria (recordar soluciones previas). 
* Muchas de estas t√©cnicas se inspiran en procesos naturales. 

**Plantilla General de una Metaheur√≠stica Basada en Poblaciones:**
1.  $P = P_0$; /* Generaci√≥n de la poblaci√≥n inicial */ 
2.  $t = 0$;
3.  **Repeat**
4.  Generar ($P'_t$); /* Generaci√≥n de una nueva poblaci√≥n */ 
5.  $P_{t+1} = \text{Select-Population}(P_t \cup P'_t)$; /* Seleccionar la nueva poblaci√≥n */ 
6.  $t = t+1$;
7.  **Until** Criterio de parada satisfecho 
8.  **Output**: Mejor(es) soluci√≥n(es) encontrada(s). 

---

### Algoritmos Evolutivos: Algoritmos Gen√©ticos (GA)

Los Algoritmos Gen√©ticos (GA) son un tipo de algoritmo evolutivo inspirado en la teor√≠a de la evoluci√≥n de Darwin: los individuos mejor adaptados al medio ambiente tienen m√°s posibilidades de sobrevivir y reproducirse, transmitiendo sus caracter√≠sticas gen√©ticas. 

**Componentes Clave de un GA:**

1.  **Representaci√≥n:** 
    * **Gen:** Unidad b√°sica de informaci√≥n (e.g., un bit, un n√∫mero).
    * **Cromosoma (Individuo):** Conjunto de genes que representa una soluci√≥n al problema.
    * **Poblaci√≥n:** Conjunto de cromosomas (individuos).

2.  **Funci√≥n de Fitness:** 
    * Mide qu√© tan "apta" es una soluci√≥n (individuo). 
    * Generalmente es la funci√≥n objetivo del problema. 
    * La probabilidad de selecci√≥n para reproducci√≥n se basa en este valor. 
    * Manejo de restricciones: Se debe decidir c√≥mo tratar a individuos que no cumplen restricciones (penalizar fitness, reparar, descartar). 

3.  **Estrategias de Selecci√≥n (Elecci√≥n de Padres):**
    * **Ruleta (Roulette Wheel Selection):** 
        * A cada individuo se le asigna una probabilidad de selecci√≥n proporcional a su fitness. 
        * Si se est√° maximizando, la probabilidad de selecci√≥n $p_i$ para el individuo $i$ con fitness $f_i$ es $p_i = f_i / (\sum f_j)$. 
        * Puede causar convergencia prematura si individuos excepcionales dominan al inicio. 
    * **Torneo (Tournament Selection):** 
        * Se seleccionan aleatoriamente K individuos de la poblaci√≥n (tama√±o del torneo K). 
        * El individuo con el mejor fitness dentro de ese grupo es elegido como padre. 
        * Se repite T veces si se necesitan T padres. 

4.  **Operadores Gen√©ticos:**
    * **Cruzamiento (Crossover):** 
        * Operador binario que combina informaci√≥n de dos padres para generar uno o m√°s hijos, heredando caracter√≠sticas. 
        * **Cruzamiento en 1-Punto:** Se elige un punto de corte aleatorio en los cromosomas padres. Los segmentos se intercambian para formar dos hijos. 
        * **Cruzamiento en 2-Puntos:** Se eligen dos puntos de corte. El material gen√©tico entre los dos puntos se intercambia. 
        * **Cruzamiento Uniforme:** Para cada gen, se decide (usualmente con una probabilidad de 0.5) de cu√°l padre heredar√° el hijo ese gen. 
    * **Mutaci√≥n:** 
        * Operador unario que introduce variabilidad alterando aleatoriamente uno o m√°s genes de un individuo. 
        * La probabilidad de mutaci√≥n ($p_m$) suele ser baja (e.g., $p_m \in [0.01, 0.05]$). 
        * Ayuda a escapar de √≥ptimos locales y a mantener la diversidad.
        * Ejemplo en dominio binario: cambiar un bit (0 a 1 o 1 a 0). 
        * Ejemplo en TSP: intercambiar dos ciudades en la ruta (swap). 

5.  **Estrategias de Reemplazo (Selecci√≥n de Sobrevivientes):** 
    * Determina qu√© individuos formar√°n la siguiente generaci√≥n, manteniendo el tama√±o de la poblaci√≥n constante. 
    * **Reemplazo Generacional:** Todos los padres son reemplazados por los hijos. 
    * **Elitismo:** Un porcentaje de los mejores individuos de la poblaci√≥n actual se mantiene directamente en la siguiente generaci√≥n. 

**Pseudoc√≥digo General de un GA:** 
1.  Generar una poblaci√≥n inicial N.
2.  Evaluar el fitness de todos los individuos.
3.  **Mientras** no se cumpla el criterio de t√©rmino:
    a.  Definir si se realizar√° mutaci√≥n o cruzamiento (seg√∫n probabilidades). 
    b.  Si es cruzamiento, seleccionar padres seg√∫n la estrategia.
    c.  Generar la siguiente generaci√≥n (considerar reemplazo generacional, elitismo, etc.). 
    d.  No olvidar guardar el mejor individuo encontrado hasta el momento. 
4.  Entregar resultados.

---

### Otros Algoritmos Evolutivos

#### Differential Evolution (DE)

Es otro algoritmo evolutivo, efectivo en problemas de optimizaci√≥n continua. 

* **Poblaci√≥n Inicial:** Se genera una poblaci√≥n inicial de $k$ individuos, donde cada individuo $X_i$ es un vector de D n√∫meros reales (punto flotante). Cada elemento $x_{ij}$ se genera aleatoriamente en un rango $[x_j^l, x_j^u]$:
    $x_{ij} = x_j^l + \text{rand}_j[0,1] \cdot (x_j^u - x_j^l)$. 
* **Mutaci√≥n y Recombinaci√≥n (Cruzamiento):** Es diferente al GA. Para cada individuo $X_i$ (padre): 
    1.  Se seleccionan aleatoriamente tres individuos distintos $r_1, r_2, r_3$ de la poblaci√≥n, diferentes de $i$. 
    2.  Se crea un vector "mutante" o "donante" $V_i$ (a menudo llamado $u_i$ en la formulaci√≥n de la diapositiva):
        $v_{ij} = x_{r_3j} + F \cdot (x_{r_1j} - x_{r_2j})$ para una de las estrategias de DE. 
        Donde $F$ es el factor de escala (diferencial), usualmente en $[0,1]$, e.g., 0.8. 
    3.  Se crea un individuo "de prueba" $U_i$ mediante cruzamiento entre el padre $X_i$ y el vector mutante $V_i$. Para cada dimensi√≥n $j$:
        $u_{ij} = v_{ij}$ si $(\text{rand}_j[0,1] < CR)$ o $(j == j_{\text{rand}})$
        $u_{ij} = x_{ij}$ en otro caso. 
        $CR$ es la tasa de cruzamiento (probabilidad), usualmente en $[0,1]$, e.g., 0.9. $j_{\text{rand}}$ asegura que al menos una variable del hijo sea del vector mutante. 
* **Selecci√≥n:** El individuo de prueba $U_i$ reemplaza al padre $X_i$ en la siguiente generaci√≥n si tiene mejor (o igual) fitness.
    $X_i(t+1) = U_i$ si $f(U_i) \le f(X_i(t))$ (para minimizaci√≥n). 
    $X_i(t+1) = X_i(t)$ en otro caso.
* **Aplicaciones:** Optimizaci√≥n continua con restricciones, funciones no diferenciables, problemas multiobjetivo. 

#### Algoritmos de Coevoluci√≥n Cooperativa

* **Concepto:** Inspirados en la evoluci√≥n complementaria de especies cercanas (e.g., plantas e insectos polinizadores). 
* A diferencia de los GA cl√°sicos, aqu√≠ m√∫ltiples poblaciones (especies) evolucionan en paralelo. 
* Cada especie desarrolla un subcomponente de la soluci√≥n global. 
* Los representantes de cada especie se unen (e.g., concatenan) para formar una soluci√≥n completa que luego es evaluada. 
* **Idea Principal:** Dividir un problema grande en subproblemas m√°s peque√±os y resolverlos de manera cooperativa e independiente. 
* **Aplicaciones:** Problemas grandes de optimizaci√≥n, entrenamiento de redes neuronales. 

#### Scatter Search

* Comienza generando una poblaci√≥n inicial diversa y de calidad. 
* Construye y mantiene un **Conjunto de Referencia (RefSet)** de tama√±o moderado (e.g., ~10 soluciones). 
* El RefSet incluye soluciones con buen fitness y otras que aportan diversidad. 
* **Proceso General:** 
    1.  Crear poblaci√≥n inicial.
    2.  Mejorar la poblaci√≥n inicial (opcionalmente usando una heur√≠stica local).
    3.  Generar el RefSet a partir de la poblaci√≥n mejorada.
    4.  Generar subconjuntos de soluciones a partir del RefSet.
    5.  Combinar soluciones de estos subconjuntos para crear nuevas soluciones.
    6.  Mejorar estas nuevas soluciones (opcionalmente).
    7.  Actualizar el RefSet con las mejores y m√°s diversas soluciones generadas.
* Integra elementos de algoritmos basados en poblaciones y de metaheur√≠sticas de una sola soluci√≥n. 

---
---

## Inteligencia de Enjambre (Swarm Intelligence)

Los algoritmos de Inteligencia de Enjambre se inspiran en el **comportamiento colectivo y social de especies** como hormigas, abejas, peces, aves, murci√©lagos, etc. Estos comportamientos surgen, por ejemplo, al competir por comida. 

* **Caracter√≠stica Principal:** La "cooperaci√≥n" mediante comunicaci√≥n indirecta entre los agentes (individuos) para explorar el espacio de b√∫squeda. 
* **Categor√≠a:** Metaheur√≠sticas basadas en poblaciones. 

### Particle Swarm Optimization (PSO)

Propuesto por James Kennedy y Russell Eberhart en 1995, el PSO se inspira en el **movimiento de las bandadas de aves** o card√∫menes de peces. 

* **Idea Central:** 
    * Inicialmente propuesto para problemas continuos.
    * La comunicaci√≥n entre "part√≠culas" (agentes) maneja el balance entre diversificaci√≥n (exploraci√≥n) e intensificaci√≥n (explotaci√≥n).

* **Conceptos Fundamentales:**
    1.  Cada **part√≠cula `i`** es una soluci√≥n candidata al problema y se representa por un vector de **posici√≥n** $X_i$ en el espacio de b√∫squeda D-dimensional. 
    2.  Cada part√≠cula tiene su propia **posici√≥n** $X_i = (x_{i1}, x_{i2}, ..., x_{iD})$ y una **velocidad** $V_i = (v_{i1}, v_{i2}, ..., v_{iD})$. La velocidad indica la direcci√≥n y la magnitud del movimiento. 
    3.  Es un algoritmo **cooperativo**: las mejores part√≠culas (o sus experiencias) influyen en el comportamiento de las dem√°s. 

**Componentes del Movimiento de una Part√≠cula:** 
Cada part√≠cula ajusta su posici√≥n bas√°ndose en dos factores principales:
1.  **La mejor posici√≥n encontrada por ella misma (experiencia personal):** Denotada como $P_i = (p_{i1}, p_{i2}, ..., p_{iD})$ (tambi√©n llamada `pbest`). 
2.  **La mejor posici√≥n encontrada por el enjambre o un subconjunto de √©l (experiencia social):** Denotada como $P_g = (p_{g1}, p_{g2}, ..., p_{gD})$ (tambi√©n llamada `gbest` o `lbest` seg√∫n el vecindario). 

**Vecindario de Part√≠culas:** 
Define la componente social y c√≥mo se comparte la informaci√≥n.
* **`gbest` (Mejor Global):** El vecindario es toda la poblaci√≥n. Todas las part√≠culas son influenciadas por la mejor soluci√≥n encontrada globalmente por cualquier part√≠cula del enjambre. (Ver imagen 'Complete graph' )
* **`lbest` (Mejor Local):** Se define una topolog√≠a (e.g., anillo, estrella) y el vecindario de una part√≠cula es un conjunto m√°s peque√±o de part√≠culas conectadas. La part√≠cula es influenciada por la mejor soluci√≥n encontrada dentro de su vecindario local. (Ver imagen 'Local structure: a ring' )

**Composici√≥n de una Part√≠cula:** 
* Vector de posici√≥n actual: $X_i(t)$. 
* Vector de la mejor posici√≥n personal encontrada: $P_i$ (`pbest`). 
* Vector de velocidad: $V_i(t)$. 

**Actualizaciones en Cada Iteraci√≥n:** 

1.  **Actualizaci√≥n de la Velocidad:** 
    La velocidad de cada part√≠cula `i` en cada dimensi√≥n `d` se actualiza como:
    $v_{id}(t) = \omega \cdot v_{id}(t-1) + c_1 \cdot \rho_{1d} \cdot (p_{id} - x_{id}(t-1)) + c_2 \cdot \rho_{2d} \cdot (p_{gd} - x_{id}(t-1))$
    Donde:
    * $v_{id}(t-1)$: Velocidad anterior.
    * $\omega$: **Peso de inercia**. Controla la influencia de la velocidad anterior. Valores grandes favorecen la exploraci√≥n global, valores peque√±os la explotaci√≥n local. 
    * $c_1, c_2$: Coeficientes de aceleraci√≥n (constantes). $c_1$ es el factor cognitivo (atracci√≥n hacia su propio mejor) y $c_2$ es el factor social (atracci√≥n hacia el mejor del vecindario). 
    * $\rho_{1d}, \rho_{2d}$: N√∫meros aleatorios uniformemente distribuidos en $[0,1]$, generados para cada dimensi√≥n y part√≠cula. Introducen un componente estoc√°stico.
    * $x_{id}(t-1)$: Posici√≥n actual (anterior a la actualizaci√≥n).
    * $p_{id}$: Mejor posici√≥n personal de la part√≠cula `i`.
    * $p_{gd}$: Mejor posici√≥n del vecindario (gbest o lbest).

    *Nota: La f√≥rmula original sin inercia es: $v_{i}(t) = v_{i}(t-1) + \rho_{1}C_{1}\times(p_{i}-x_{i}(t-1)) + \rho_{2}C_{2}\times(g_{i}-x_{i}(t-1))$.* 

2.  **Actualizaci√≥n de la Posici√≥n:** 
    La nueva posici√≥n se calcula sumando la nueva velocidad a la posici√≥n actual:
    $x_{id}(t) = x_{id}(t-1) + v_{id}(t)$ 

3.  **Actualizaci√≥n de las Mejores Posiciones:** 
    * **Actualizar `pbest`:** Si la nueva posici√≥n $X_i(t)$ es mejor (seg√∫n la funci√≥n de fitness $f$) que $P_i$, entonces $P_i = X_i(t)$.
      `Si f(xi) < f(pbesti) Entonces pbesti = xi` (para minimizaci√≥n) 
    * **Actualizar `gbest` (o `lbest`):** Si la nueva posici√≥n $X_i(t)$ es mejor que la actual $P_g$, entonces $P_g = X_i(t)$.
      `Si f(xi) < f(gbest) Entonces gbest = xi` (para minimizaci√≥n y usando gbest) 

**Representaci√≥n Gr√°fica del Movimiento:** 
Una part√≠cula en $x(t)$ se mueve a $x(t+1)$ influenciada por su velocidad actual $v(t)$, su mejor experiencia personal $p_i$, y la mejor experiencia de sus vecinos $p_g$.

**Pseudoc√≥digo del PSO:** 
1.  Inicializar aleatoriamente la poblaci√≥n de part√≠culas (posiciones $X_i$ y velocidades $V_i$).
2.  Para cada part√≠cula, inicializar $P_i = X_i$.
3.  Identificar $P_g$ entre todos los $P_i$.
4.  **Repeat**
5.  Para cada part√≠cula $i$:
    a.  Evaluar $f(X_i)$.
    b.  Actualizar $P_i$ si $f(X_i)$ es mejor que $f(P_i)$.
    c.  Actualizar $P_g$ si $f(X_i)$ es mejor que $f(P_g)$ (o el $P_{lbest}$ correspondiente).
    d.  Actualizar velocidad $V_i(t)$ usando la ecuaci√≥n de velocidad. 
    e.  Actualizar posici√≥n $X_i(t) = X_i(t-1) + V_i(t)$. 
    f.  `If f(xi) < f(pbesti) Then pbesti = xi` 
    g.  `If f(xi) < f(gbest) Then gbest = xi` 
6.  **Until** Criterio de parada satisfecho (e.g., n√∫mero de iteraciones, convergencia). 
7.  **Output**: $P_g$ (la mejor soluci√≥n encontrada).

**Par√°metros del algoritmo**
- $C_1$
- $C_2$
- $w$
- N (Cantidad de individuos)

## Actividad

Se busca encontrar el m√≠nimo de la funci√≥n:
$f(x) = \sum_{i=1}^{N-1} [100(x_{i+1} - x_i^2)^2 + (1 - x_i)^2]$
donde $x_i \in [-10, 10]$ y $N=3$. Para $N=3$, la funci√≥n es:
$f(x_1, x_2, x_3) = [100(x_2 - x_1^2)^2 + (1 - x_1)^2] + [100(x_3 - x_2^2)^2 + (1 - x_2)^2]$

Dados los siguientes par√°metros de una part√≠cula en un algoritmo PSO:

A. Posici√≥n actual de la part√≠cula: $x(t-1) = (x_1, x_2, x_3) = (0.4, 1.2, -3.2)$
B. Mejor posici√≥n personal: $p = (p_1, p_2, p_3) = (1.2, 2.5, -2.1)$
C. Mejor posici√≥n global: $g = (g_1, g_2, g_3) = (1.4, 1.1, -0.4)$
D. Constantes del PSO: $C_1 = 1$, $C_2 = 1$, $\omega = 1$
E. Velocidad actual de la part√≠cula: $v(t-1) = (v_1, v_2, v_3) = (-0.8, 0.2, -1.2)$
F. N√∫meros aleatorios proporcionados: Se utilizar√° $\rho_1 = 0.21$ para el componente cognitivo y $\rho_2 = 0.43$ para el componente social.

Se pide calcular la nueva posici√≥n de la part√≠cula $x(t)$.

---

### Resoluci√≥n

Las ecuaciones para la actualizaci√≥n de la velocidad y la posici√≥n de una part√≠cula en PSO son:

1.  **Actualizaci√≥n de la velocidad (para cada dimensi√≥n $d$):**
    $v_d(t) = \omega \cdot v_d(t-1) + C_1 \cdot \rho_1 \cdot (p_d - x_d(t-1)) + C_2 \cdot \rho_2 \cdot (g_d - x_d(t-1))$

2.  **Actualizaci√≥n de la posici√≥n (para cada dimensi√≥n $d$):**
    $x_d(t) = x_d(t-1) + v_d(t)$

En este c√°lculo, utilizaremos $\rho_1 = 0.21$ y $\rho_2 = 0.43$ como los n√∫meros aleatorios escalares aplicados a los componentes cognitivo y social, respectivamente, para todas las dimensiones.

#### Paso 1: Calcular la nueva velocidad $v(t)$

* **Para la dimensi√≥n 1 ($d=1$):**
    $v_1(t-1) = -0.8$
    $x_1(t-1) = 0.4$
    $p_1 = 1.2$
    $g_1 = 1.4$
    $v_1(t) = (1 \cdot -0.8) + (1 \cdot 0.21 \cdot (1.2 - 0.4)) + (1 \cdot 0.43 \cdot (1.4 - 0.4))$
    $v_1(t) = -0.8 + (0.21 \cdot 0.8) + (0.43 \cdot 1.0)$
    $v_1(t) = -0.8 + 0.168 + 0.43$
    $v_1(t) = -0.8 + 0.598$
    $v_1(t) = -0.202$

* **Para la dimensi√≥n 2 ($d=2$):**
    $v_2(t-1) = 0.2$
    $x_2(t-1) = 1.2$
    $p_2 = 2.5$
    $g_2 = 1.1$
    $v_2(t) = (1 \cdot 0.2) + (1 \cdot 0.21 \cdot (2.5 - 1.2)) + (1 \cdot 0.43 \cdot (1.1 - 1.2))$
    $v_2(t) = 0.2 + (0.21 \cdot 1.3) + (0.43 \cdot -0.1)$
    $v_2(t) = 0.2 + 0.273 - 0.043$
    $v_2(t) = 0.2 + 0.23$
    $v_2(t) = 0.43$

* **Para la dimensi√≥n 3 ($d=3$):**
    $v_3(t-1) = -1.2$
    $x_3(t-1) = -3.2$
    $p_3 = -2.1$
    $g_3 = -0.4$
    $v_3(t) = (1 \cdot -1.2) + (1 \cdot 0.21 \cdot (-2.1 - (-3.2))) + (1 \cdot 0.43 \cdot (-0.4 - (-3.2)))$
    $v_3(t) = -1.2 + (0.21 \cdot (-2.1 + 3.2)) + (0.43 \cdot (-0.4 + 3.2))$
    $v_3(t) = -1.2 + (0.21 \cdot 1.1) + (0.43 \cdot 2.8)$
    $v_3(t) = -1.2 + 0.231 + 1.204$
    $v_3(t) = -1.2 + 1.435$
    $v_3(t) = 0.235$

Por lo tanto, la nueva velocidad es $v(t) = (-0.202, 0.43, 0.235)$.

#### Paso 2: Calcular la nueva posici√≥n $x(t)$

* **Para la dimensi√≥n 1 ($d=1$):**
    $x_1(t) = x_1(t-1) + v_1(t)$
    $x_1(t) = 0.4 + (-0.202)$
    $x_1(t) = 0.198$

* **Para la dimensi√≥n 2 ($d=2$):**
    $x_2(t) = x_2(t-1) + v_2(t)$
    $x_2(t) = 1.2 + 0.43$
    $x_2(t) = 1.63$

* **Para la dimensi√≥n 3 ($d=3$):**
    $x_3(t) = x_3(t-1) + v_3(t)$
    $x_3(t) = -3.2 + 0.235$
    $x_3(t) = -2.965$

La nueva posici√≥n de la part√≠cula es $x(t) = (0.198, 1.63, -2.965)$.

Verificamos si los componentes de la nueva posici√≥n est√°n dentro del dominio $x_i \in [-10, 10]$:
* $x_1(t) = 0.198$ (Dentro del rango)
* $x_2(t) = 1.63$ (Dentro del rango)
* $x_3(t) = -2.965$ (Dentro del rango)
Todos los componentes est√°n dentro de los l√≠mites permitidos.

---

**Respuesta Final:**
La nueva posici√≥n de la part√≠cula es $x(t) = (0.198, 1.63, -2.965)$.

# Clase 22-05-25

## Sintonizaci√≥n de Par√°metros

La sintonizaci√≥n de par√°metros es un problema fundamental y costoso en el dise√±o de Algoritmos Exactos y Metaheur√≠sticas (MHs). Consiste en asignar valores a los elementos num√©ricos de un algoritmo para optimizar su rendimiento.

### Decisiones de Dise√±o en MHs

Diferentes metaheur√≠sticas tienen par√°metros espec√≠ficos que requieren sintonizaci√≥n:

- **Tabu Search**: Tama√±o de la lista Tab√∫.
    
- **Simulated Annealing**: Temperatura inicial, par√°metro de enfriamiento, y cantidad de iteraciones para enfriamiento y calentamiento.
    
- **Algoritmos Gen√©ticos (GA)**: Probabilidad de cruzamiento/mutaci√≥n, operadores y porcentaje de elitismo.
    
- **ACO**: Tasa de evaporaci√≥n.
    
- **PSO**: Ponderaci√≥n global best-local best-inertia.
    

### Consideraciones Clave

Un buen algoritmo debe explorar el espacio de b√∫squeda y luego explotar las zonas favorables. Los par√°metros est√°n interrelacionados, lo que complejiza el proceso de dise√±o. Los valores de los par√°metros se determinan a partir de un conjunto de benchmarks.

### Sintonizaci√≥n vs. Control

Es importante diferenciar entre sintonizaci√≥n y control de par√°metros:

- **Sintonizaci√≥n**: Proceso previo a la ejecuci√≥n del algoritmo, consume mucho tiempo, y los valores de los par√°metros son fijos durante la ejecuci√≥n. (Estrategia offline)
    
- **Control**: Proceso que ocurre durante la ejecuci√≥n del algoritmo, con valores variables, y puede ser din√°mico, adaptativo o auto-adaptativo. (Estrategia online)
    

### T√©cnicas de Sintonizaci√≥n de Par√°metros

Existen varias t√©cnicas para la sintonizaci√≥n de par√°metros:

- **Manual**: Ajuste manual de los par√°metros.
    
- **Estad√≠stica (Racing)**: Basada en pruebas estad√≠sticas, donde los algoritmos son evaluados iterativamente y eliminados si se encuentra evidencia de inferioridad. Un ejemplo es el test de Friedman. Ejemplos incluyen Pygmo e irace.
    
- **Meta-Algoritmos**: Utilizan otros algoritmos para encontrar la mejor configuraci√≥n de par√°metros.
    - **B√∫squeda Local**: Consiste en experimentar cambiando un par√°metro y aceptando la nueva configuraci√≥n solo si mejora el desempe√±o. Esto puede optimizarse con Iterated Local Search (ILS).
        
    - **ParamILS**: Un ejemplo de meta-algoritmo que utiliza un enfoque de b√∫squeda local iterativa con perturbaci√≥n y un criterio de aceptaci√≥n para encontrar la mejor configuraci√≥n de par√°metros.
        

### An√°lisis de Desempe√±o en MHs

Para analizar el desempe√±o de las metaheur√≠sticas, se consideran:

- **Dise√±o experimental**: Selecci√≥n de benchmarks.
    
- **Mediciones**: An√°lisis estad√≠stico de resultados (tiempo de CPU, valor de la funci√≥n objetivo) y comparaci√≥n con t√©cnicas del estado del arte.
    
- **Reporte**: Gr√°ficos de convergencia, gr√°ficos de cajas, reporte de tiempo de CPU y generaciones, asegurando la reproducibilidad de los experimentos.

